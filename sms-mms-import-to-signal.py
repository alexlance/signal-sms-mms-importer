import xml.etree.ElementTree as ET
import sys
import os
import sqlite3
import base64
import time
import logging
import argparse

parser = argparse.ArgumentParser(
                    description = 'imports SMS and MMS messages in to a Signal Backup')

parser.add_argument('args',nargs='*')
parser.add_argument('--input', '-i', help='input sms backup xml file')
parser.add_argument('--output', '-o', help='exported signal backup to update')
parser.add_argument('--merge', '-m', dest='merge', action='store_true', help="optional argument, to delete any instances of the same sms/mms prior to inserting. useful if this isn't your first time")
parser.add_argument('--verbose', '-v', dest='verbose', action='store_true', help='turns logging from info/warning only, to every debug item')

args = parser.parse_args()

input = args.input if args.input is not None else args.args[0]
output = args.output if args.output is not None else args.args[1]

logging.basicConfig(filename='signalsmsmmsimport.log', filemode='a', format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S', level=logging.DEBUG if args.verbose else logging.INFO)

#todo:
# finish mms/rcs message import correction
# make them dictionaries instead of lists where possible (readability/performance)
# make a reliable equivalent to oracle merge? delete/add? update? optional arguments/yesno prompts to ask about the 'delete equivalent things' prcoess?
# create recipient when not exist?
# have mms/sms appear as such in signal, not as signal messages
# handle group things

logging.info(f"input file is '{input}', output file is '{output}'")

def get_contacts(cursor):
    cursor.execute("select _id, phone, system_display_name from recipient")
    contacts = cursor.fetchall()
    contacts_by_number = {}
    for c in contacts:
        if c[1]:
            contacts_by_number[c[1]] = c[0]
            contacts_by_number[c[1].replace("+61", "0")] = c[0]
            contacts_by_number[c[1].replace("+61", "0").replace("-", "")] = c[0]
    return contacts_by_number


def get_parts(r):
    rtn = []
    # print("GETTING PARTS:")
    for parts in r.findall("parts"):
        for part in parts.findall("part"):
            rtn.append(part)
    return rtn


def get_addrs(r):
    rtn = []
    # print("GETTING ADDRS:")
    for addrs in r.findall("addrs"):
        for addr in addrs.findall("addr"):
            rtn.append(addr)
    return rtn

def add_recipient(add):
    cursor.execute(f"""insert into recipient (phone, default_subscription_id, registered) values ("{add}", 1, 2)""")
    conn.commit()
    contacts_by_number = get_contacts(cursor)
    contacts_by_number[add]
    return contacts_by_number, contacts_by_number[add]

# parse the XML file generated by SMS Backup and Restore (by SyncTech)
logging.info('starting parsing xml file')
tree = ET.parse(input)
root = tree.getroot()
logging.info('finished parsing xml file')

# parse the sqlite database generated by github.com/bepaald/signalbackup-tools
conn = sqlite3.connect(os.path.join(output, "database.sqlite"))
cursor = conn.cursor()

smses = []
mmses = []
contacts_by_number = get_contacts(cursor)

for r in root:
    date_sent = r.attrib.get("date_sent","")
    if date_sent in [0, "0", ""]:
        date_sent = r.attrib.get("date","")
    address = False
    add = r.attrib["address"].replace("-", "").replace("+61","0")
    add_list = []
    if '~' in add:
        for a in sorted(add.split("~")):
            try:
                address = contacts_by_number[a]
                #logging.info(f"Coerced group of {add} to a single contact: {a}")
            except KeyError:
                contacts_by_number, address = add_recipient(a)
                #pass
            finally:
                add_list.append(address)
    if not address:
        try:
            address = contacts_by_number[add]
        except KeyError:
            contacts_by_number, address = add_recipient(add)
    if r.tag == "sms":
        # magic Signal numbers
        #typ = 87 if str(r.attrib["type"]) == "2" else 20
        #sms sent is type 87, sms received is type 20
        row = {}
        row['add_list'] = add_list
        row['address'] = address
        row['date'] = r.attrib["date"]
        row['date_sent'] = date_sent
        row['read'] = 1  # "read"
        row['status'] = -1  # "status"
        row['type'] = 87 if str(r.attrib["type"]) == "2" else 20
        row['body'] = r.attrib["body"]
        smses.append(row)
    elif r.tag == "mms":
        # magic Signal numbers, 10485783 for messages we've sent, 10485780 for messages we've received
        #typ = 128 if str(r.attrib["msg_box"]) == "2" else 132
        #m_type is correct, r[5] (message box) 87 is sent inc text, 20 is received using text, 23 is no text
        #addrs = get_addrs(r)
        parts = get_parts(r)
        text = ""
        for text_part in parts:
            if text_part.get("seq") == '0':
                text = text_part.get("text","")
                if text == "null":
                    text =""
        row = {}
        row['add_list'] = add_list
        row['address'] = address
        row['date'] = r.attrib["date"]
        row['date_sent'] = date_sent
        row['read'] = 1  # "read"
        row['status'] = -1  # "status",
        row['typ'] = 128 if str(r.attrib["msg_box"]) == "2" else 132
        row['body'] = r.attrib.get("body", text)
        if row['typ'] == 128:
            if row['body'] == '':
                row['m_typ'] = 23
            else:
                row['m_typ'] = 87
        elif row['typ'] == 132:
            row['m_typ'] = 20
        row['parts'] = parts
        row['addrs'] = get_addrs(r)
        mmses.append(row)

logging.info(f"Found {str(len(smses))} sms")
logging.info(f"Found {str(len(mmses))} mms")

time.sleep(3)


def get_or_make_thread(cursor, r, doUpdate=False, doDelete=False):
    thread_id = False
    cursor.execute(f"select _id from thread where thread_recipient_id = '{r['address']}'")
    rows = cursor.fetchall()
    if len(rows):
        thread_id = rows[0][0]
    if thread_id:
        if doUpdate:
            # print("Updating thread:", thread_id, r)
            cursor.execute(
                "update thread set date = ?, message_count = message_count + 1, snippet = ? where _id = ?",
                (r['date'], str(r['body'])[0:100], thread_id),)
        if doDelete:
            cursor.execute(f"update thread set message_count = message_count - 1 where _id = {thread_id}")
    else:
        # print("Creating new thread:", r)
        cursor.execute(
            "insert into thread (date, thread_recipient_id, message_count, snippet) VALUES (?, ?, ?, ?)",
            (r['date'], r['address'], 1, str(r['body'])[0:100]),
        )
        cursor.execute("select max(_id) as thread_id from thread")
        rows = cursor.fetchone()
        if len(rows):
            thread_id = rows[0]
    return thread_id

if args.merge:
    logging.info("deleting existing mms to replace")
    i = 0
    for r in mmses:
        if not len(r.get('add_list')):
            r['add_list'].append(r.get('address'))
        add_list = r.get('add_list')
        for add in add_list:
            cursor.execute(f"select _id as mms_id from mms where address = {add} and date = {r['date']}")
            result = cursor.fetchall()
            for row in result:
                mms_id = row[0]
                cursor.execute(f"select _id, unique_id from part where mid = '{mms_id}'")
                parts = cursor.fetchall()
                for part in parts:
                    part_id = part[0]
                    unique_id = part[1]
                    fname = os.path.join(output, f"Attachment_{part_id}_{unique_id}.bin")
                    fname2 = os.path.join(output,f"Attachment_{part_id}_{unique_id}.sbf")
                    try:
                        os.remove(fname)
                    except:
                        pass
                    try:
                        os.remove(fname2)
                    except:
                        pass
                cursor.execute(f"delete from part where mid = '{mms_id}'")
                cursor.execute(f"delete from mms where _id = '{mms_id}'")
        i = i + 1
        if i % 1000 == 0:
            conn.commit()
    else:
        conn.commit()

logging.info("inserting mms")

for r in mmses:
    thread_id = get_or_make_thread(cursor, r)
    part_count = len(r['parts'])
    #m_type = 128  # 128 == we sent
    #if r[5] == 10485780:
        #m_type = 132  # 132 == we received
    #m_type is correct, r[5] (message box) 87 is sent inc text, 20 is received using text, 23 is no text
    logging.debug(f"Writing MMS: {r}")
    q = "INSERT INTO mms ( \
           thread_id, date, date_received, date_server, msg_box, read, body, part_count, address, \
           delivery_receipt_count, read_receipt_count, viewed_receipt_count, m_type) \
         VALUES \
           (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)"
    cursor.execute(
        q,
        (thread_id, r['date'], r['date_sent'], r['date'], r['typ'], 1, r['body'], part_count, r['address'], 1, 1, 1, r['m_typ']),
    )
    #conn.commit()
    cursor.execute("select max(_id) as mms_id from mms")
    rows = cursor.fetchall()
    mms_id = rows[0][0]
    seq = 0
    logging.debug(f"PARTS found {len(r['parts'])} parts")
    for part in r['parts']:
        # skip smil - not sure if Signal undestand SMIL formatting
        if int(part.attrib.get("seq", 0)) != -1 and part.attrib.get("data"):
            seq += 1
            logging.debug(f"  Working on mms {mms_id} part number {seq}")
            data = base64.b64decode(part.attrib["data"])
            data_size = len(data)
            file_name = part.attrib.get("name", part.attrib.get("cl", ""))
            # something needs to be tweaked around here, file names are still coming across as null
            if file_name == "" or file_name == "null":
                file_name = part.attrib.get("cid", "")
            file_name = (
                file_name.replace("&lt;", "")
                .replace("&gt;", "")
                .replace("<", "")
                .replace(">", "")
            )
            unique_id = int(time.time() * 1000)
            logging.debug(f"    -> file: {file_name} is {data_size} bytes")
            props = '{"skipTransform":true,"videoTrim":false,"videoTrimStartTimeUs":0,"videoTrimEndTimeUs":0,"sentMediaQuality":0,"videoEdited":false}'
            q = "INSERT INTO part (mid, seq, ct, name, chset, data_size, file_name, unique_id, caption, transform_properties) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)"
            cursor.execute(
                q,
                (
                    mms_id,
                    seq,
                    part.attrib.get("ct"),
                    file_name,
                    file_name,
                    # part.attrib.get("chset"),
                    data_size,
                    file_name,
                    unique_id,
                    part.attrib.get("text", ""),
                    props
                ),
            )
            cursor.execute("select max(_id) as part_id from part")
            rows = cursor.fetchall()
            part_id = rows[0][0]
            # dump the attachments in the folder the way that signalbackup-tools likes to have them
            fname = f"{output}/Attachment_{part_id}_{unique_id}.bin"
            fname2 = f"{output}/Attachment_{part_id}_{unique_id}.sbf"
            with open(fname, "wb") as f:
                logging.debug(f"      * writing: {fname}")
                f.write(data)
            fdesc = f"ROWID:uint64:{part_id}\n\
ATTACHMENTID:uint64:{unique_id}\n\
LENGTH:uint32:{data_size}"
            with open(fname2, "w") as f:
                logging.debug(f"      * writing: {fname2}")
                f.write(fdesc)
    i = i + 1
    if i % 1000:
        conn.commit()
else:
    conn.commit()

logging.info("mms inserted")

# process normal smses too (this tends to be slower cause there's generally more of them)

if args.merge:
    logging.info(f"Deleting sms to be inserted")
    cursor.execute("create index sms_del on sms (address, date);")
    for r in smses:
        cursor.execute(f"delete from sms where address = '{r['address']}' and date = '{r['date']}';")
        i = i + 1
        if i % 1000 == 0:
            conn.commit()
    else:
        conn.commit()
        cursor.execute("drop index sms_del;")

logging.info("inserting sms")
for r in smses:
    r['thread_id'] = get_or_make_thread(cursor=cursor, r=r)
    logging.debug(f"Writing SMS: {r}")
    cursor.execute(
        """INSERT INTO sms (thread_id, address, date, date_sent, read, status, type, body, delivery_receipt_count, read_receipt_count)
        VALUES (:thread_id, :address, :date, :date_sent, :read, :status, :type, :body, 1, 1)""",
        (r['thread_id'], r['address'], r['date'], r['date_sent'], r['read'], r['status'], r['type'], r['body'])
    )
    i = i + 1
    if i % 1000 == 0:
        conn.commit()
else:
    conn.commit()

logging.info("sms inserted")

conn.commit()
cursor.close()

logging.info("complete")